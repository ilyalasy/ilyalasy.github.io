---
---
@inproceedings{arzt-etal-2024-tu,
    title = "{TU} {W}ien at {S}em{E}val-2024 Task 6: Unifying Model-Agnostic and Model-Aware Techniques for Hallucination Detection",
    author = "Arzt, Varvara  and
      Azarbeik, Mohammad Mahdi  and
      Lasy, Ilya  and
      Kerl, Tilman  and
      Recski, G{\'a}bor",
    editor = {Ojha, Atul Kr.  and
      Do{\u{g}}ru{\"o}z, A. Seza  and
      Tayyar Madabushi, Harish  and
      Da San Martino, Giovanni  and
      Rosenthal, Sara  and
      Ros{\'a}, Aiala},
    booktitle = "Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)",
    month = jun,
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.semeval-1.173/",
    doi = "10.18653/v1/2024.semeval-1.173",
    pages = "1183--1196",
    abstract = "This paper discusses challenges in Natural Language Generation (NLG), specifically addressing neural networks producing output that is fluent but incorrect, leading to ``hallucinations''. The SHROOM shared task involves Large Language Models in various tasks, and our methodology employs both model-agnostic and model-aware approaches for hallucination detection. The limited availability of labeled training data is addressed through automatic label generation strategies. Model-agnostic methods include word alignment and fine-tuning a BERT-based pretrained model, while model-aware methods leverage separate classifiers trained on LLMs' internal data (layer activations and attention values). Ensemble methods combine outputs through various techniques such as regression metamodels, voting, and probability fusion. Our best performing systems achieved an accuracy of 80.6{\%} on the model-aware track and 81.7{\%} on the model-agnostic track, ranking 3rd and 8th among all systems, respectively."
}
